{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "import mglearn\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# A.",
   "id": "59c5d5fd6003badc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# The file has no headers naming the columns, so we pass header=None\n",
    "# and provide the column names explicitly in \"names\"\n",
    "data = pd.read_csv(\n",
    "\"/home/andy/datasets/adult.data\", header=None, index_col=False,\n",
    "names=['age', 'workclass', 'fnlwgt', 'education',  'education-num',\n",
    "'marital-status', 'occupation', 'relationship', 'race', 'gender',\n",
    "'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "'income'])\n",
    "# For illustration purposes, we only select some of the columns\n",
    "data = data[['age', 'workclass', 'education', 'gender', 'hours-per-week',\n",
    "'occupation', 'income']]\n",
    "# IPython.display allows nice output formatting within the Jupyter notebook\n",
    "display(data.head())\n",
    "print(data.gender.value_counts())\n",
    "print(\"Original features:\\n\", list(data.columns), \"\\n\") \n",
    "data_dummies = pd.get_dummies(data)\n",
    "print(\"Features after get_dummies:\\n\", list(data_dummies.columns))\n",
    "data_dummies.head()\n",
    "features = data_dummies.ix[:, 'age':'occupation_ Transport-moving']\n",
    "# Extract NumPy arrays\n",
    "X = features.values\n",
    "y = data_dummies['income_ >50K'].values\n",
    "print(\"X.shape: {}  y.shape: {}\".format(X.shape, y.shape))\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "print(\"Test score: {:.2f}\".format(logreg.score(X_test, y_test)))\n",
    "# create a DataFrame with an integer feature and a categorical string feature\n",
    "demo_df = pd.DataFrame({'Integer Feature': [0, 1, 2, 1],\n",
    " 'Categorical Feature': ['socks', 'fox', 'socks', 'box']})\n",
    "display(demo_df)\n",
    "pd.get_dummies(demo_df)\n",
    "demo_df['Integer Feature'] = demo_df['Integer Feature'].astype(str)\n",
    "pd.get_dummies(demo_df, columns=['Integer Feature', 'Categorical Feature'])"
   ],
   "id": "147917edd661973d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#. B",
   "id": "e13b5a3b21ee6146"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "cancer = load_breast_cancer()\n",
    "# get deterministic random numbers\n",
    "rng = np.random.RandomState(42)\n",
    "noise = rng.normal(size=(len(cancer.data), 50))\n",
    "# add noise features to the data\n",
    "# the first 30 features are from the dataset, the next 50 are noise\n",
    "X_w_noise = np.hstack([cancer.data, noise])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_w_noise, cancer.target, random_state=0, test_size=.5)\n",
    "# use f_classif (the default) and SelectPercentile to select 50% of features\n",
    "select = SelectPercentile(percentile=50)\n",
    "select.fit(X_train, y_train)\n",
    "# transform training set\n",
    "X_train_selected = select.transform(X_train)\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_train_selected.shape: {}\".format(X_train_selected.shape))\n",
    "mask = select.get_support()\n",
    "print(mask)\n",
    "# visualize the mask -- black is True, white is False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "# transform test data\n",
    "X_test_selected = select.transform(X_test)\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(\"Score with all features: {:.3f}\".format(lr.score(X_test,y_test)))\n",
    "lr.fit(X_train_selected, y_train)\n",
    "print(\"Score with only selected features: {:.3f}\".format(\n",
    "lr.score(X_test_selected, y_test)))\n",
    "select = SelectFromModel(\n",
    "RandomForestClassifier(n_estimators=100, random_state=42),\n",
    " threshold=\"median\")\n",
    "select.fit(X_train, y_train)\n",
    "X_train_l1 = select.transform(X_train)\n",
    "print(\"X_train.shape: {}\".format(X_train.shape))\n",
    "print(\"X_train_l1.shape: {}\".format(X_train_l1.shape))\n",
    "mask = select.get_support()\n",
    "# visualize the mask -- black is True, white is False\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "X_test_l1 = select.transform(X_test)\n",
    "score = LogisticRegression().fit(X_train_l1, y_train).score(X_test_l1, y_test)\n",
    "print(\"Test score: {:.3f}\".format(score))\n",
    "select = RFE(RandomForestClassifier(n_estimators=100, random_state=42),\n",
    " n_features_to_select=40)\n",
    "select.fit(X_train, y_train)\n",
    "# visualize the selected features:\n",
    "mask = select.get_support()\n",
    "plt.matshow(mask.reshape(1, -1), cmap='gray_r')\n",
    "plt.xlabel(\"Sample index\")\n",
    "X_train_rfe= select.transform(X_train)\n",
    "X_test_rfe= select.transform(X_test)\n",
    "score = LogisticRegression().fit(X_train_rfe, y_train).score(X_test_rfe, y_test)\n",
    "print(\"Test score: {:.3f}\".format(score))\n",
    "print(\"Test score: {:.3f}\".format(select.score(X_test, y_test)))"
   ],
   "id": "be39994143ce2fa5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# C.",
   "id": "52860f0f2872a36e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mglearn.plots.plot_pca_illustration()\n",
    "fig, axes = plt.subplots(15, 2, figsize=(10, 20))\n",
    "malignant = cancer.data[cancer.target == 0]\n",
    "benign = cancer.data[cancer.target == 1]\n",
    "ax = axes.ravel()\n",
    "for i in range(30):\n",
    " _, bins = np.histogram(cancer.data[:, i], bins=50)\n",
    " ax[i].hist(malignant[:, i], bins=bins, color=mglearn.cm3(0), alpha=.5)\n",
    " ax[i].hist(benign[:, i], bins=bins, color=mglearn.cm3(2), alpha=.5)\n",
    " ax[i].set_title(cancer.feature_names[i])\n",
    " ax[i].set_yticks(())\n",
    "ax[0].set_xlabel(\"Feature magnitude\")\n",
    "ax[0].set_ylabel(\"Frequency\")\n",
    "ax[0].legend([\"malignant\", \"benign\"], loc=\"best\")\n",
    "fig.tight_layout()\n",
    "cancer = load_breast_cancer()\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(cancer.data)\n",
    "X_scaled = scaler.transform(cancer.data)\n",
    "# keep the first two principal components of the data\n",
    "pca = PCA(n_components=2)\n",
    "# fit PCA model to breast cancer data\n",
    "pca.fit(X_scaled)\n",
    "# transform data onto the first two principal components\n",
    "X_pca = pca.transform(X_scaled)\n",
    "print(\"Original shape: {}\".format(str(X_scaled.shape)))\n",
    "print(\"Reduced shape: {}\".format(str(X_pca.shape)))\n",
    "# plot first vs. second principal component, colored by class\n",
    "plt.figure(figsize=(8, 8))\n",
    "mglearn.discrete_scatter(X_pca[:, 0], X_pca[:, 1], cancer.target)\n",
    "plt.legend(cancer.target_names, loc=\"best\")\n",
    "plt.gca().set_aspect(\"equal\")\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")\n",
    "print(\"PCA component shape: {}\".format(pca.components_.shape))\n",
    "print(\"PCA components:\\n{}\".format(pca.components_))\n",
    "plt.matshow(pca.components_, cmap='viridis')\n",
    "plt.yticks([0, 1], [\"First component\", \"Second component\"])\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(cancer.feature_names)),\n",
    "cancer.feature_names, rotation=60, ha='left')\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Principal components\")\n",
    "people = fetch_lfw_people(min_faces_per_person=20, resize=0.7)\n",
    "image_shape = people.images[0].shape\n",
    "fix, axes = plt.subplots(2, 5, figsize=(15, 8),\n",
    "subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for target, image, ax in zip(people.target, people.images, axes.ravel()):\n",
    " ax.imshow(image)\n",
    " ax.set_title(people.target_names[target])\n",
    " \n",
    "print(\"people.images.shape: {}\".format(people.images.shape))\n",
    "print(\"Number of classes: {}\".format(len(people.target_names)))\n",
    "# count how often each target appears\n",
    "counts = np.bincount(people.target)\n",
    "# print counts next to target names\n",
    "for i, (count, name) in enumerate(zip(counts, people.target_names)):\n",
    " print(\"{0:25} {1:3}\".format(name, count), end='   ')\n",
    " if (i + 1) % 3 == 0: print()\n",
    "mask = np.zeros(people.target.shape, dtype=np.bool)\n",
    "for target in np.unique(people.target):\n",
    " mask[np.where(people.target == target)[0][:50]] = 1\n",
    "X_people = people.data[mask]\n",
    "y_people = people.target[mask]\n",
    "# scale the grayscale values to be between 0 and 1\n",
    "# instead of 0 and 255 for better numeric stability\n",
    "X_people = X_people / 255.\n",
    "# split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "X_people, y_people, stratify=y_people, random_state=0)\n",
    "# build a KNeighborsClassifier using one neighbor\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, y_train)\n",
    "print(\"Test set score of 1-nn: {:.2f}\".format(knn.score(X_test, y_test)))\n",
    "mglearn.plots.plot_pca_whitening()\n",
    "pca = PCA(n_components=100, whiten=True, random_state=0).fit(X_train)\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print(\"X_train_pca.shape: {}\".format(X_train_pca.shape))\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train_pca, y_train)\n",
    "print(\"Test set accuracy: {:.2f}\".format(knn.score(X_test_pca, y_test)))\n",
    "print(\"pca.components_.shape: {}\".format(pca.components_.shape))\n",
    "fix, axes = plt.subplots(3, 5, figsize=(15, 12),\n",
    "subplot_kw={'xticks': (), 'yticks': ()})\n",
    "for i, (component, ax) in enumerate(zip(pca.components_, axes.ravel())):\n",
    " ax.imshow(component.reshape(image_shape),\n",
    "cmap='viridis')\n",
    " ax.set_title(\"{}. component\".format((i + 1)))\n",
    "mglearn.plots.plot_pca_faces(X_train, X_test, image_shape)\n",
    "mglearn.discrete_scatter(X_train_pca[:, 0], X_train_pca[:, 1], y_train)\n",
    "plt.xlabel(\"First principal component\")\n",
    "plt.ylabel(\"Second principal component\")"
   ],
   "id": "d8f1dc29487b855c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# D.",
   "id": "943442365621eb81"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# generate dataset\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "# plot dataset\n",
    "mglearn.discrete_scatter(X[:, 0], X[:, 1], y)\n",
    "plt.legend([\"Class 0\", \"Class 1\"], loc=4)\n",
    "plt.xlabel(\"First feature\")\n",
    "plt.ylabel(\"Second feature\")\n",
    "print(\"X.shape: {}\".format(X.shape))\n",
    " \n",
    "X, y = mglearn.datasets.make_wave(n_samples=40)\n",
    "plt.plot(X, y, 'o')\n",
    "plt.ylim(-3, 3)\n",
    "plt.xlabel(\"Feature\")\n",
    "plt.ylabel(\"Target\")\n",
    " \n",
    "cancer = load_breast_cancer()\n",
    "print(\"cancer.keys(): \\n{}\".format(cancer.keys()))\n",
    " \n",
    "print(\"Shape of cancer data: {}\".format(cancer.data.shape))\n",
    "  \n",
    "print(\"Sample counts per class:\\n{}\".format(\n",
    "{n: v for n, v in zip(cancer.target_names, np.bincount(cancer.target))}))\n",
    "   \n",
    "print(\"Feature names:\\n{}\".format(cancer.feature_names))\n",
    "\n",
    "boston = load_boston()\n",
    "print(\"Data shape: {}\".format(boston.data.shape))\n",
    "\n",
    "X, y = mglearn.datasets.load_extended_boston()\n",
    "print(\"X.shape: {}\".format(X.shape))\n",
    "mglearn.plots.plot_knn_classification(n_neighbors=1)\n",
    "mglearn.plots.plot_knn_classification(n_neighbors=3)\n",
    "\n",
    "X, y = mglearn.datasets.make_forge()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "clf = KNeighborsClassifier(n_neighbors=3)\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"Test set predictions: {}\".format(clf.predict(X_test)))\n",
    "print(\"Test set accuracy: {:.2f}\".format(clf.score(X_test, y_test)))\n",
    "   \n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 3))\n",
    "for n_neighbors, ax in zip([1, 3, 9], axes):\n",
    " # the fit method returns the object self, so we can instantiate\n",
    " # and fit in one line\n",
    " clf = KNeighborsClassifier(n_neighbors=n_neighbors).fit(X, y)\n",
    " mglearn.plots.plot_2d_separator(clf, X, fill=True, eps=0.5, ax=ax, alpha=.4)\n",
    " mglearn.discrete_scatter(X[:, 0], X[:, 1], y, ax=ax)\n",
    " ax.set_title(\"{} neighbor(s)\".format(n_neighbors))\n",
    " ax.set_xlabel(\"feature 0\")\n",
    " ax.set_ylabel(\"feature 1\")\n",
    "axes[0].legend(loc=3)   \n",
    " \n",
    "cancer = load_breast_cancer()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "cancer.data, cancer.target, stratify=cancer.target, random_state=66)\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try n_neighbors from 1 to 10\n",
    "neighbors_settings = range(1, 11)\n",
    "for n_neighbors in neighbors_settings:\n",
    " # build the model\n",
    " clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    " clf.fit(X_train, y_train)\n",
    " # record training set accuracy\n",
    " training_accuracy.append(clf.score(X_train, y_train))\n",
    " # record generalization accuracy\n",
    " test_accuracy.append(clf.score(X_test, y_test))\n",
    " plt.plot(neighbors_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(neighbors_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.legend()"
   ],
   "id": "990592152dfa5713"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
